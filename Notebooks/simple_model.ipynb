{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import PIL\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score, f1_score, log_loss\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "from transformers import AutoModelForImageClassification, AutoImageProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc36734865a49a3beaeeb9ac36871e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glob, test folder\n",
    "test_paths = [pth.split(\"/\")[-1] for pth in glob('../data/test/*')]\n",
    "test_df = pd.DataFrame(sorted(test_paths, key=lambda x: int(x.split(\".\")[0])), columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed= 42\n",
    "train_df, validation_df = train_test_split(\n",
    "    train_df, test_size=0.1, stratify=train_df[\"label\"].values, random_state=seed\n",
    ")\n",
    "validation_df, holdout_df = train_test_split(\n",
    "    validation_df, test_size=0.5, stratify=validation_df[\"label\"].values, random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.reset_index(drop=True, inplace=True)\n",
    "validation_df.reset_index(drop=True, inplace=True)\n",
    "holdout_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\"NO_AI\": 0, \"AI\": 1}\n",
    "id2label = {0: \"NO_AI\", 1: \"AI\"}\n",
    "\n",
    "class data(torch.utils.data.Dataset):\n",
    "    def __init__(self, train_labels: pd.DataFrame = train_df, split_name:str = 'train', aug_transforms=None):\n",
    "        self.train_labels = train_labels\n",
    "        self.index = train_labels.index\n",
    "        self.split_name = split_name\n",
    "        self.aug_transforms = aug_transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "            \n",
    "        try :\n",
    "            name = self.train_labels.loc[index, \"id\"]\n",
    "            if self.split_name == \"train\":\n",
    "                label = self.train_labels.loc[index, \"label\"]    \n",
    "        except IndexError:\n",
    "            raise IndexError('Index out of range')\n",
    "        \n",
    "        path = f'../data/{self.split_name}/{name}'\n",
    "        # image = plt.imread(path)\n",
    "        image = PIL.Image.open(path)\n",
    "        image = self.aug_transforms(image)\n",
    "        \n",
    "        if self.split_name == \"train\":\n",
    "            return {\"img_path\": path, \"image\": image, \"label\": label}\n",
    "        else:\n",
    "            return {\"img_path\": path, \"image\": image}\n",
    "    \n",
    "    def info(self):\n",
    "        print(f'Number of images: {len(self)}')\n",
    "        print(f'Classes: {self.train_labels[\"label\"].unique()}')\n",
    "        print(f'Images shape : {self[0][0].shape}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BeitForImageClassification were not initialized from the model checkpoint at microsoft/beit-base-patch16-224-pt22k-ft22k and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([21841, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([21841]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "# model_ckpt = \"microsoft/swin-tiny-patch4-window7-224\"\n",
    "model_ckpt = \"microsoft/beit-base-patch16-224-pt22k-ft22k\"\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    model_ckpt, \n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    ignore_mismatched_sizes = True,\n",
    ")\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = image_processor.image_mean, image_processor.image_std\n",
    "size = image_processor.size[\"height\"]\n",
    "\n",
    "\n",
    "train_transforms = T.Compose([\n",
    "    T.RandomResizedCrop(size),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=mean, std=std)\n",
    "])\n",
    "test_transforms = T.Compose([\n",
    "    T.Resize(size),\n",
    "    T.CenterCrop(size),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data(train_df, split_name='train', aug_transforms=train_transforms)\n",
    "validation_dataset = data(validation_df, split_name='train', aug_transforms=test_transforms)\n",
    "holdout_dataset = data(holdout_df, split_name='test', aug_transforms=test_transforms)\n",
    "test_dataset = data(test_df, split_name='test', aug_transforms=test_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "\n",
    "model_name = model_ckpt.split(\"/\")[-1]\n",
    "batch_size = 64\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-aiornot-simple\",\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    # learning_rate=5e-5,\n",
    "    # learning_rate=4e-5,\n",
    "    learning_rate=7e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    # num_train_epochs=3,\n",
    "    num_train_epochs=20,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    f1 = f1_score(labels, preds, average=\"macro\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    logloss = log_loss(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"log_loss\": logloss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"image\"] for example in examples])\n",
    "    try :\n",
    "        labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "        return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "    except :\n",
    "        return {\"pixel_values\": pixel_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/projects/hg_airornot/Notebooks/beit-base-patch16-224-pt22k-ft22k-aiornot-simple is already a clone of https://huggingface.co/mustapha/beit-base-patch16-224-pt22k-ft22k-aiornot-simple. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer \n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=image_processor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 16756\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 1300\n",
      "  Number of trainable parameters = 85763522\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='78' max='1300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  78/1300 12:04 < 3:14:05, 0.10 it/s, Epoch 1.18/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "      <th>Steps Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.181100</td>\n",
       "      <td>2.013179</td>\n",
       "      <td>0.143033</td>\n",
       "      <td>0.944146</td>\n",
       "      <td>0.942982</td>\n",
       "      <td>14.141200</td>\n",
       "      <td>65.836000</td>\n",
       "      <td>1.061000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 931\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to beit-base-patch16-224-pt22k-ft22k-aiornot-simple/checkpoint-65\n",
      "Configuration saved in beit-base-patch16-224-pt22k-ft22k-aiornot-simple/checkpoint-65/config.json\n",
      "Model weights saved in beit-base-patch16-224-pt22k-ft22k-aiornot-simple/checkpoint-65/pytorch_model.bin\n",
      "Image processor saved in beit-base-patch16-224-pt22k-ft22k-aiornot-simple/checkpoint-65/preprocessor_config.json\n",
      "Image processor saved in beit-base-patch16-224-pt22k-ft22k-aiornot-simple/preprocessor_config.json\n",
      "Deleting older checkpoint [beit-base-patch16-224-pt22k-ft22k-aiornot-simple/checkpoint-1170] due to args.save_total_limit\n"
     ]
    }
   ],
   "source": [
    "train_results = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(holdout_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=256, pin_memory=True\n",
    ")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = []\n",
    "# pred_ids = []\n",
    "\n",
    "for batch in test_loader:\n",
    "    image_paths = batch[\"img_path\"]\n",
    "    image_paths = [x.split(\"/\")[-1] for x in image_paths]\n",
    "    file_paths.extend(image_paths)\n",
    "    \n",
    "#     images = batch[\"image\"].to(device)\n",
    "#     inputs = {\"pixel_values\": images}\n",
    "    \n",
    "#     with torch.no_grad(): \n",
    "#         # logits = model(**inputs).logits\n",
    "#         logits = trainer.predict(**inputs).logits\n",
    "\n",
    "#     # predictions = logits.argmax(-1).cpu().numpy().tolist()\n",
    "#     predictions = torch.nn.Softmax(dim=1)(logits)[:,1].cpu().numpy().tolist()\n",
    "#     pred_ids.extend(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = data(test_df, split_name='test', aug_transforms=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = torch.nn.functional.softmax(torch.tensor(trainer.predict(test_dataset).predictions), dim=1)[:,1].cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_ids = [1-x for x in pred_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_df = pd.DataFrame({\"id\": file_paths, \"label\": pred_ids})\n",
    "submission_df = pd.DataFrame({\"id\": file_paths, \"label\": all_predictions})\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "submission_df.to_csv(f\"{TIMESTAMP}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.state.log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "16c46821c1401faaf5ad31213b2dfd6fcbee6ba139ce43836ce7acccacfff6dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
